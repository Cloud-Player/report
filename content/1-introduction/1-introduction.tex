\section{Introduction}
With the rise of social media and a wide adoption of connected devices that can produce multimedia the internet is shifting from a content consuming towards a content producing audience. Nowadays everyone can take a photo or record a video and share it to an audience with the press of a button. 

Live broadcasting is also not reserved to professional media companies anymore. Network infrastructure is rapidly improving, especially the availability of mobile bandwidth. With the advent of 5G an estimated 2.?? billion people will have access to bandwidths of up to XX??. In combination with ever more powerful consumer devices, users are able to produce and publish content in professional quality e.g. the latest generation of smartphones can produce videos in resolutions up to XX??k.
Leveraging these new possibilities, platforms like Twitch, Periscope and IGTV have emerged that allow anyone with access to the internet to share live video with large audiences.

These platforms run vast cloud architectures to deliver video in realâ€“time across the globe and already account for XXpercent of global internet traffic.
Netflix a popular \gls{vod} platform recommends an internet connection speed of 5.0 Megabits per second for an HD quality video \cite{netflix-speed-recommendation}. In 2017, users of the video streaming platform Persicope have streamed 350,000 hours of video per day \cite{periscope-stats} which is over 4h/s. 
Assuming an average bandwidth consumption of 5.0 Megabits/s and multiplying it with the amount of video that is streamed per second, the Periscope infrastructure has to handle around 70 Gigabits/s.
Providing an infrastructure to deal with 70 Gigabits/s of video data is very expensive. Also scaling the system to a growing number of users can be a non trivial task and can become impossible at some point.

Yet, a cloud architecture is not only expensive, it is also a single point of failure. When the cloud architecture is taken off by a failure or by an attack, the service can not be used anymore.
From the point of a user it also means losing control of data because all the data is sent to the cloud which is under the control of the provider. Thus, the provider has the power to monitor users and is also able to censorship content based on political views or believes.

To mitigate the issues of a cloud architecture a lot of research has been put into Peer-to-Peer systems. Peer-to-Peer systems do not have a central point but distribute traffic among themselves. Every peer can consume content and provide content at the same time, thereby a central distribution point is not required anymore. Through the introduction of Napster in 1999, a Peer-to-Peer driven music streaming service, Peer-to-Peer systems have become popular. Since then multiple other Peer-to-Peer systems like BitTorrent, Gnutella and most recently IPFS have hit the market. BitTorrent is well known to be used for filesharing. As it has proven itself to support more than a million daily active users \cite{bittorrent-stats}, the protocol also has become interesting for business use cases as well e.g. sychronising databases or updating servers


\paragraph{Random Intro quotes}
\say{It can be expected that the number and importance of such distributed applications will grow with time as the Internet is penetrating more and more into our lives.} (https://www.cs.vu.nl/pub/steen/papers/wip-newscast.pdf \S1)

\say{The popularity of peer-to-peer systems in the last couple of years illustrates how the Internet is gradually shifting toward a distributed system that supports more than only client-server applications.}(https://link.springer.com/content/pdf/10.1007\%2F978-3-540-25840-7\_6.pdf \S1)

das gabs ja auch mal
was war damit verkehrt
und jetzt browser
ah und dann kam auf einmal webrtc
mhmm appearin macht das ja schon damit aber nur 1-4
und was war noch mit ipfs claiming to be the future of http

However, all platforms are based on a centralised client-server architecture. Sharing a multicast video means consuming a lot of bandwaith especially on the server that is distributing the content. This maintaining a centralised server to handle 

- network congestion, multicast beschde
- Privacy/Zensur
- Kostenfaktor
- browser immer besser #webrtc



\subsection{Thesis aufbau}
- looked at the underlying tech of ipfs, webrtc, p2p, meshing
- construct overlay
- let streams hop
- analyse our stuff
- works good for what apps/ use cases #framework


- webrtc/browsers and distributed stuff #blockchain on the rise
- ipfs promises to be future of web, the next http
- didnt work for live streams #nucleus
- tried nucleus y-adapter, hopping video
- how can we replace manual setup with automated system for many ppl
